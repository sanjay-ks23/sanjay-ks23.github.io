---
layout: post
title:  "An intuitive understanding of Gradient Descent and its successors"
author: sanjay
categories: [ Machine Learning ]
image: assets/images/posts/Gradient descent.png
---

In my previous post, I discussed loss functions in detail. and in this blog, we are going to go really indepth about Gradient Descent one of the ways to minimise these loss function and also look into their successors in greater detail.

Let us start with the basics and my opinion on Machine Learning,

## What is Machine Learning according me?
During my undergrad one of my professors has the best possible analogy for Machine Learning, even though I didnt quite understand it back then, after working in the field for a while I can say that it is quite accurate. Take a box which has an irregular shape and can take up any shape it is being fitted into. Now think of the box under extreme force to mak it fit into the shape, by fitting it we try to make the fit as perfect as possible while taking multiple things into consideration. Now how this correlates to Machine Learning is that the box is the model, the shape is the data. The model tries to fit into the data.